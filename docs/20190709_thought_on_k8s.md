# Thoughts on Kubernetes

I started to get interested in Docker container about 4 years ago after I left OpenStack cloud computing development at IBM software lab. Comparing Docker and Kubernetes (even they're not exactly working at the same layer, because Kubernetes still uses Docker underneath, and K8S is more like orchestration to integrate and bridge between containerized workloads) I've done lots of solution design and practices on docker, such as clustered MongoDB, Redis, and Kafka (they're all modern NoSQL-style databases to handle/ process data, tremendously running faster than traditional SQL DB), based on Docker. Fun and helpful to me to understand the in-depth technology of Docker.

My solutions were sticky on Docker, because I figured that K8S is more fat and heavier than native Docker. Until late of last year, I found and realized that K8S had concrete ability of managing __high-availability, fault-tolerance, load-balancing, journal/ logging monitoring__ much more integrated into K8S-self and workload. I give you an example, you can make a MongoDB cluster on docker configuring in a specific clustering method. So are others for Kafka, PostgreSQL, Redis clusters. These are not all to the end. Other than clustering, for load-balancing, high-availability, as highlighted above, you need to manually configure and manage respectively. The required skill is high. And they're all different.

However, Kubernetes will handle them all in a very standard way, It eliminates the variety of configuration and consolidates and simplifies operation, while reducing the respective skill requirement. Kubernetes is conquering the infrastructure, platform and all of their orchestration/ management/ configuration/ operation in one place, simply split into 2 layers inside = control plane and data plane.

Kubernetes works exactly as Service-Oriented-Architecture (SOA), which rose up more than 10 years ago. SOA has never be landed in technology perspective. It was a dreamed design on presentation. Kubernetes really makes this come true in code on keyboard. Another example, when you want to launch a business application, you'll need CPU, virtual machine, network by software-defined-network (SDN), database on persistent volume (disk), security isolation, communication encryption by SSL. They're all individual works of design and development... these works certainly take month to complete/ test/ on-production... On Kubernetes, they are all standardized and simplified dominantly. When this kind of business application is no longed needed, each of computing resource needs removed one-by-one in old operation model. In Kubernetes, they can possibly be removed all-in-one step...

In term of operation, monitoring is very critical and essential. It's easy to understand. In traditional operation model, monitoring needs to be configured individually to each of application stack respectively. You'd monitor each of application, middleware, database, front-end web service, underneath operating system, network... In Kubernetes, the natively integrated Prometheus takes over the all to send out alters on-demand or launching new component to replace the mal-functional ones, instead of fixing it. You won't be called to launch if any of pieces is down abnormally.

What I can say from now, Kubernetes would standardize from __architecture design, application development/ test, production deployment and on-going operation/ maintenance, across the entire life-cycle of DevOps__. It's also changing both technical aspect and business model. This has not been realized by most of IT business people. Someday, they may lose their jobs without noticing why.

IoT (KubeEdge to manage remote end-point, launching daemon when it dies without human involved, plus integrated SSL encryption) and EDA (Kubernetes Istio Knative pipelining) are absolutely under this umbrella!

Kubernetes is changing the information technology industry.

The following blog comes from https://developer.ibm.com/code/2017/07/21/service-mesh-architecture-and-istio/ by Animesh Singh, as reference 

Microservices and containers have changed application design and deployment patterns. They’ve also brought with them some new challenges, such as service discovery, routing, failure handling, and visibility to microservices. And while PaaS platforms like Cloud Foundry are great for deploying microservices, they were created with a view of simplifying application deployment across multiple runtimes. Similarly, Kubernetes can handle multiple container-based workloads, including microservices, but when it comes to more sophisticated features like traffic management, failure handling, and resiliency, both the platforms leave a lot to be desired. Imagine an application that is broken down into multiple microservices; each microservice has multiple instances, and each deployed instance has multiple versions. Typically, even a simple application deployment with this kind of model can span hundreds of microservices. When an application deployment gets this large, distributed, and complex, the result is often failure. But you need to fail fast and recover quickly. You need a mechanism that is fault-tolerant, one that provides more visibility and control into the complex network of microservices and ensures reliable, secure, and timely communication between them. For this deployment model, we need to keep track of the traffic flow between microservices, route traffic for microservices based on request content or traffic origination point, and handle failures in a graceful manner when a number of microservices are not reachable. We also need to enforce strong identity assertion between services and limit the entities that can access a service. Most importantly, we want to do all this without changing the application code. Service mesh architecture was created to handle these requirements. Think of a service mesh as a network of interconnected devices with routers and switches, except in this case the network exists at the application layer (layer 7), nodes are services, and routing, delivery, and other tasks are off-loaded to the service mesh. The goal is to get a request in a reliable, secure and timely manner across this mesh of microservices from origination to destination microservice. Typically, this is achieved by using “proxies” to intercept all incoming and outgoing network traffic. Proxies in a service mesh architecture are implemented using the sidecar pattern: a sidecar is conceptually attached to the main (or parent) application and complements that parent by providing platform features. With this kind of model, your microservice can use the sidecar either as a set of processes inside the same microservice container or as a sidecar in its own container to leverage platform capabilities such as routing, load balancing, resiliency, in-depth monitoring, and access control.
